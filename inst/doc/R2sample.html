<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>R2sample</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">R2sample</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(R2sample)</span></code></pre></div>
<p>This package brings together a number of routines for the two sample
problem for univariate data. There are two data sets x and y and we want
to test whether they were generated by the same probability
distribution.</p>
<p>The highlights of this package are:</p>
<ul>
<li>it runs a large number of tests simultaneously.<br />
</li>
<li>the user can provide their own tests<br />
</li>
<li>it works for continuous and for discrete data.<br />
</li>
<li>it uses a permutation test to find p values (except for chi square
tests).</li>
<li>user can also provide a routine to generate simulated data for the
goodness-of-fit/twosample hybrid problem<br />
</li>
<li>tests can be combined and a single adjusted p value found<br />
</li>
<li>for large continuous data sets p values can be found via large
sample theory.</li>
<li>it uses Rcpp and parallel programming to be very fast.<br />
</li>
<li>it includes routines that make power studies very simple.<br />
</li>
<li>it has a routine that runs (up to) 20 different case studies,
comparing the power of a new method to those included in the package.
This will make it very easy for someone who has developed a new method
to compare its performance vs. those included in the package.</li>
</ul>
<div id="example-1" class="section level2">
<h2>Example 1</h2>
<p>We generate two data sets of size 100 and 120 respectively from
standard normal distributions and run the test:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>y1 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">120</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="fu">twosample_test</span>(x1, y1, <span class="at">B=</span><span class="dv">500</span>)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper      CvM       AD       LR       ZA       ZK       ZC </span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co">#&gt;   0.1383   0.1666   0.3363   1.6834   0.6655  -3.2530   2.4087  -3.1940 </span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#&gt;   Wassp1 ES large ES small EP large EP small </span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt;   0.2224  16.0900   5.1700  34.8500   8.8000 </span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper      CvM       AD       LR       ZA       ZK       ZC </span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt;   0.0000   0.0000   0.0000   0.0000   0.0000   0.0000   1.0000   0.0000 </span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt;   Wassp1 ES large ES small EP large EP small </span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&gt;   0.0000   0.8846   0.5228   0.2482   0.4559</span></span></code></pre></div>
<p>In this case the the null hypothesis is true, both data sets were
generated by a standard normal distribution. And indeed, all 13 tests
have p values much larger than (say) 0.05 and therefore correctly fail
to reject the null hypothesis.</p>
<p>Alternatively one might wish to carry out a select number of tests,
but then find a correct p value for the combined test. This can be done
as follows:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">twosample_test_adjusted_pvalue</span>(x1, y1)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt; p values of individual tests:</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#&gt; ES small :  0.5228</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt; ZA :  0.6394</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; ZK :  0.5792</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; Wassp1 :  0.8626</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt; Kuiper :  0.6156</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt; adjusted p value of combined tests: 0.965</span></span></code></pre></div>
<p>By default for continuous data this runs four tests (chi square with
a small number of bins, ZA, ZK and Wassp1). It the finds the smallest p
value (here 0.02) and adjusts it for the multiple testing problem,
resulting in an overall p value of 0.05.</p>
<div id="new-tests" class="section level3">
<h3>New Tests</h3>
<p>Say we wish to use two new tests for continuous data. One is based on
the difference in standardized means and the other is based on the
difference in standard deviations:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;TS_1 = sd(x) - sd(y) \\
&amp;TS_2 = \bar{x}/sd(x) - \bar{y}/sd(y) \\
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>myTS1 <span class="ot">=</span> <span class="cf">function</span>(x, y) {</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>   out <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>   out[<span class="dv">1</span>] <span class="ot">=</span> <span class="fu">abs</span>(<span class="fu">sd</span>(x) <span class="sc">-</span> <span class="fu">sd</span>(y))</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>   out[<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">abs</span>(<span class="fu">mean</span>(x)<span class="sc">/</span><span class="fu">sd</span>(x) <span class="sc">-</span> <span class="fu">mean</span>(y)<span class="sc">/</span><span class="fu">sd</span>(y))</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>   <span class="fu">names</span>(out) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;std&quot;</span>, <span class="st">&quot;std t test&quot;</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>   out</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>}</span></code></pre></div>
<p>Then we can simply run</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">twosample_test</span>(x1, y1, <span class="at">TS=</span>myTS1, <span class="at">B=</span><span class="dv">500</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co">#&gt;        std std t test </span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#&gt;    0.06396    0.18060 </span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt;        std std t test </span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt;      0.560      0.178</span></span></code></pre></div>
<div id="arguments-and-output-of-new-test-routine-for-continuous-data" class="section level4">
<h4>Arguments and output of new test routine for continuous data</h4>
<p>The arguments have to be x and y for the two data sets and
(optionally) a list called TSextra for any additional input needed to
find test statistic.</p>
<p>Note that the output vector of the routine has to be a
<strong>named</strong> vector. If the routine is written in Rcpp
parallel programming is not available.</p>
</div>
</div>
</div>
<div id="example-2" class="section level2">
<h2>Example 2</h2>
<p>Here we generate two data sets of size 1000 and 1200 respectively
from a binomial distribution with 5 trials and success probabilities of
0.5 and 0.55, respectively.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>,<span class="fu">rbinom</span>(<span class="dv">1000</span>, <span class="dv">5</span>, <span class="fl">0.5</span>)))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>y2 <span class="ot">=</span> <span class="fu">table</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>,<span class="fu">rbinom</span>(<span class="dv">1200</span>, <span class="dv">5</span>, <span class="fl">0.55</span>)))<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="fu">rbind</span>(x2, y2)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">#&gt;     0   1   2   3   4  5</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">#&gt; x2 37 126 321 345 149 22</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co">#&gt; y2 29 127 351 383 241 69</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="fu">twosample_test</span>(x2, y2, <span class="at">vals=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">B=</span><span class="dv">500</span>)<span class="sc">$</span>p.values</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">#&gt;     KS Kuiper    CvM     AD     LR     ZA Wassp1  large  small </span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co">#&gt;      0      0      0      0      0      0      0      0      0</span></span></code></pre></div>
<p>In this case the the null hypothesis is false, all nine tests for
discrete data have p values much smaller than (say) 0.05 and therefore
correctly reject the null hypothesis.</p>
<p>Notice, it is the presence of the <em>vals</em> argument that tells
the <em>twosample_test</em> command that the data is discrete. The
vectors x and y are the counts. Note that the lengths of the three
vectors have to be the same and no value of vals is allowed that has
both x and y equal to 0.</p>
<div id="new-test" class="section level3">
<h3>New Test</h3>
<p>Again we might want to run a different test, say based again on the
difference in standardized means. This time we will implement the new
test using Rcpp:</p>
<p>(For reasons to do with submission to CRAN this routine is already
part of <em>R2sample</em>)</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="kw">using</span> <span class="kw">namespace</span> Rcpp<span class="op">;</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>NumericVector myTS2<span class="op">(</span>IntegerVector x<span class="op">,</span> </span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>                         IntegerVector y<span class="op">,</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>                         NumericVector vals<span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>  </span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>  Rcpp<span class="op">::</span>CharacterVector methods<span class="op">=</span>CharacterVector<span class="op">::</span>create<span class="op">(</span><span class="st">&quot;std t test&quot;</span><span class="op">);</span>    </span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>  <span class="dt">int</span> <span class="at">const</span> nummethods<span class="op">=</span>methods<span class="op">.</span>size<span class="op">();</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>  <span class="dt">int</span> k<span class="op">=</span>x<span class="op">.</span>size<span class="op">(),</span> n<span class="op">=</span>sum<span class="op">(</span>x<span class="op">),</span> i<span class="op">;</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>  <span class="dt">double</span> meanx<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> meany<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> sdx<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> sdy<span class="op">=</span><span class="fl">0.0</span><span class="op">;</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>  NumericVector TS<span class="op">(</span>nummethods<span class="op">);</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>  TS<span class="op">.</span>names<span class="op">()</span> <span class="op">=</span>  methods<span class="op">;</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>  <span class="cf">for</span><span class="op">(</span>i<span class="op">=</span><span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>k<span class="op">;++</span>i<span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    meanx <span class="op">=</span> meanx <span class="op">+</span> x<span class="op">[</span>i<span class="op">]*</span>vals<span class="op">[</span>i<span class="op">]/</span>n<span class="op">;</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    meany <span class="op">=</span> meany <span class="op">+</span> y<span class="op">[</span>i<span class="op">]*</span>vals<span class="op">[</span>i<span class="op">]/</span>n<span class="op">;</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>  <span class="cf">for</span><span class="op">(</span>i<span class="op">=</span><span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>k<span class="op">;++</span>i<span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    sdx <span class="op">=</span> sdx <span class="op">+</span> x<span class="op">[</span>i<span class="op">]*(</span>vals<span class="op">[</span>i<span class="op">]</span> <span class="op">-</span> meanx<span class="op">)*(</span>vals<span class="op">[</span>i<span class="op">]</span> <span class="op">-</span> meanx<span class="op">);</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    sdy <span class="op">=</span> sdy <span class="op">+</span> y<span class="op">[</span>i<span class="op">]*(</span>vals<span class="op">[</span>i<span class="op">]</span> <span class="op">-</span> meany<span class="op">)*(</span>vals<span class="op">[</span>i<span class="op">]</span> <span class="op">-</span> meany<span class="op">);</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>  <span class="op">}</span>  </span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>  sdx <span class="op">=</span> sqrt<span class="op">(</span>sdx<span class="op">/(</span>n<span class="op">-</span><span class="dv">1</span><span class="op">));</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>  sdy <span class="op">=</span> sqrt<span class="op">(</span>sdy<span class="op">/(</span>n<span class="op">-</span><span class="dv">1</span><span class="op">));</span></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>  TS<span class="op">(</span><span class="dv">0</span><span class="op">)</span> <span class="op">=</span> <span class="bu">std::</span>abs<span class="op">(</span>meanx<span class="op">/</span>sdx <span class="op">-</span> meany<span class="op">/</span>sdy<span class="op">);</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>  <span class="cf">return</span> TS<span class="op">;</span></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Now</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">twosample_test</span>(x2, y2, <span class="at">vals=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">TS=</span>R2sample<span class="sc">::</span>myTS2, <span class="at">B=</span><span class="dv">500</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt; std t test </span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">#&gt;    0.03927 </span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="co">#&gt; std t test </span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co">#&gt;          1</span></span></code></pre></div>
<div id="arguments-and-output-of-new-test-routine-for-discrete-data" class="section level4">
<h4>Arguments and output of new test routine for discrete data</h4>
<p>The arguments have to be x and y for the two data sets (the counts)
and vals for the set of values where <span class="math inline">\(P(X=vals)&gt;0\)</span>. Also (optionally) a list
called TSextra for any additional input needed to find test
statistic.</p>
<p>Note that the output vector of the routine has to be a
<strong>named</strong> vector.</p>
<p>If the routine is written in Rcpp parallel programming is not
available.</p>
</div>
</div>
</div>
<div id="permutation-method" class="section level2">
<h2>Permutation Method</h2>
<p>For all the tests except the chi square variants the p values are
found via the permutation method. The idea of a permutation test is
simple. Say we have data sets <span class="math inline">\(x_1,..,x_n\)</span> and <span class="math inline">\(y_1,..,y_m\)</span>. They are combined into one
large data set, permuted and split again in sets of sizes n and m. Under
the null hypothesis these new data sets come from the same distribution
as the actual data. Therefore calculating the tests statistics for them
and repeating many times one can build up the distributions of the test
statistics and find p values from them.</p>
<p>In the discrete case the situation is somewhat more complicated. Say
we have data sets with values <span class="math inline">\(v_1,..,v_k\)</span> and counts <span class="math inline">\(x_1,..,x_n\)</span>, <span class="math inline">\(y_1,..,y_k\)</span>. One can then mimic the
description above by expanding these to yield a large data set with
<span class="math inline">\(x_1+y_1\)</span> <span class="math inline">\(v_1\)</span>’s, <span class="math inline">\(x_2+y_2\)</span> <span class="math inline">\(v_2\)</span>’s and so on. Then this vector is
permuted and split as described above. The drawback of this sampling
method is that its calculation speed increases with the sample size.
Alternatively R2sample provides the following option. One can show that
the distribution of the permuted data sets has the following
distribution: let <span class="math inline">\(n=\sum x_i\)</span> and
<span class="math inline">\(m=\sum y_i\)</span>, then</p>
<p><span class="math display">\[P(X=a|x,y)=\frac{\prod_{j=1}^k{{x_j+y_j}\choose{a_j}}}{{n+m}\choose{n}}\]</span>
for any <span class="math inline">\(a\)</span> such that <span class="math inline">\(0\le a_i \le x_i; i=1,..,k\)</span> and <span class="math inline">\(\sum a=n\)</span>. Sampling from this distribution
can be done using MCMC. R2sample uses the Metropolis-Hastings algorithm
as follows: in each step two coordinates <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> with <span class="math inline">\(1\le
i,j \le k, i\ne j\)</span> are chosen randomly. Then the proposal <span class="math inline">\(a_i=x_i+1, a_j=x_j-1, b_i=y_i-1,
b_j=y_j+1\)</span>, <span class="math inline">\(a=x, b=y\)</span> is
accepted with probability</p>
<p><span class="math display">\[\frac{P(X=a|x,y)}{P(X=x|x,y)}=\frac{(x_i+y_i-a_i)a_j}{(x_j+y_j+1-a_j)(a_i+1)}\]</span>
As is generally the case with MCMC simulation one needs a larger number
of simulations than with independence sampling. The default is
independence sampling size with a simulation size of 5000 for testing
and (1000, 1000) for power estimation. If the sample sizes are very
large this might run quite slowly and it might be advisable to change to
samplingmethod=“MCMC”.</p>
<p>Of course MCMC sampling suffers from the usual issues of having to
reach the stationary distribution. In the current situation a two-sample
test is likely only done if the two data sets are reasonably close, and
so the MCMC algorithm should start essentially at the stationary
distribution and no burn-in period is required.</p>
<p>On a standard pc (as of 2024) independence sampling of two data sets
with 10000 observation each takes only a few seconds and so is perfectly
doable.</p>
</div>
<div id="parametric-bootstrap" class="section level2">
<h2>Parametric Bootstrap</h2>
<p>The user can also provide a routine <em>rnull</em>, which generates
new data under the null hypothesis. This is needed in the following
situation: we wish to perform a goodness-of-fit test <span class="math inline">\(H_0:X\sim F(p)\)</span>, where <span class="math inline">\(F\)</span> is some distribution function that
depends on unknown parameters <span class="math inline">\(p\)</span>.
These parameters can be estimated from the data by <span class="math inline">\(\hat{p}\)</span>. Unfortunately <span class="math inline">\(F\)</span> is complicated and can not be evaluated
directly. We can, however, sample from <span class="math inline">\(F(\hat{p})\)</span>. So we generate a second data
set <span class="math inline">\(y\)</span> from <span class="math inline">\(F(\hat{p})\)</span>. In this setup the permutation
method fails, and the p values have to be found via the parametric
bootstrap.</p>
</div>
<div id="example-3" class="section level2">
<h2>Example 3</h2>
<p>Say we have a data set <span class="math inline">\(x\)</span> and
wish to test whether it comes from a normal distribution with unknown
mean and standard deviation. Let’s assume we do not know how to evalute
the normal cdf, so instead we sample from <span class="math inline">\(N(\bar{x}, sd(x))\)</span>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>rnull<span class="ot">=</span><span class="cf">function</span>(dta) {</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>   <span class="fu">list</span>(<span class="at">x=</span>dta<span class="sc">$</span>x,</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>        <span class="at">y=</span><span class="fu">rnorm</span>(<span class="fu">length</span>(dta<span class="sc">$</span>y), <span class="fu">mean</span>(dta<span class="sc">$</span>x), <span class="fu">sd</span>(dta<span class="sc">$</span>x)))</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>}</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="fu">twosample_test</span>(x1, y1, <span class="at">rnull=</span>rnull, <span class="at">B=</span><span class="dv">500</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper      CvM       AD       LR       ZA       ZK       ZC </span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">#&gt;   0.1383   0.1666   0.3363   1.6834   0.6655  -3.2530   2.4087  -3.1940 </span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">#&gt;   Wassp1 ES large ES small EP large EP small </span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co">#&gt;   0.2224  16.0900   5.1700  34.8500   8.8000 </span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co">#&gt;       KS   Kuiper      CvM       AD       LR       ZA       ZK       ZC </span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co">#&gt;   0.0560   0.1480   0.0140   0.0120   0.0160   0.1000   0.1220   0.0740 </span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a><span class="co">#&gt;   Wassp1 ES large ES small EP large EP small </span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a><span class="co">#&gt;   0.0080   0.8846   0.5228   0.2482   0.4559</span></span></code></pre></div>
<p>The routine <em>rnull</em> has to have as its argument a list with
the data sets and return an object of the same type.</p>
</div>
<div id="the-testing-methods" class="section level2">
<h2>The Testing Methods</h2>
<p>In the continuous case we have a sample x of size of n and a sample y
of size m. In the discussion below both are assumed to be ordered. We
denote by z the combined sample. In the discrete case we have a random
variable with values v, and x and y are the counts. We denote by k the
number of observed values.</p>
<p>We denote the edf’s of the two data sets by <span class="math inline">\(\widehat{F}\)</span> and <span class="math inline">\(\widehat{G}\)</span>, respectively. Moreover we
denote the empirical distribution function of the combined data set by
<span class="math inline">\(\widehat{H}\)</span>.</p>
<ul>
<li><strong>chi large</strong></li>
</ul>
<p>In the case of continuous data, it is binned into <em>nbins[1]</em>
equal probability bins, with the default <em>nbins[1]=100</em>. In the
case of discrete data the number of classes comes from <em>vals</em>,
the values observed.</p>
<p>Then a standard chi square test is run and the p value is found using
the usual chi square approximation.</p>
<ul>
<li><strong>chi small</strong></li>
</ul>
<p>Many previous studies have shown the a chi square test with a large
number of classes often has very poor power. So this test in the case of
continuous data uses <em>nbins[2]</em> equal probability bins, with the
default <em>nbins[2]=10</em>. In the case of discrete data if the number
of classes exceeds <em>nbins[2]=10</em> the classes are combined until
there are <em>nbins[2]=10</em> classes.</p>
<p>In either case the p values are found using the usual chi-square
approximation. The degrees of freedom are the number of bins. For a
literature review of chi square tests see <span class="citation">(W.
Rolke 2021)</span>.</p>
<hr />
<p>For all other tests the p values are found using a permutation test.
They are</p>
<ul>
<li><strong>KS</strong> Kolmogorov-Smirnov test</li>
</ul>
<p>This test is based on the quantity <span class="math inline">\(\max\{|\widehat{F}(x)-\widehat{G}(x)|:x\in
\mathbf{R}\}\)</span>. In the continuous case (without ties) the
function <span class="math inline">\(\widehat{F}(x)-\widehat{G}(x)\)</span> either
takes a jump of size <span class="math inline">\(1/n\)</span> up at a
point in the x data set, a jump of size <span class="math inline">\(1/m\)</span> down if x is a point in the y data
set, or is flat. Therefore the test statistic is</p>
<p><span class="math display">\[\max\{\sum_{i=1}^{j} \vert \frac1n
I\{z_i \in x\}-\frac1m I\{z_i \in y\} \vert:j=1,..,n+m\}\]</span></p>
<p>In the discrete case the jumps have sizes <span class="math inline">\(x_i/n\)</span> and <span class="math inline">\(y_j/m\)</span>, respectively and the test
statistic is</p>
<p><span class="math display">\[\max\{\sum_{i=1}^{j} \vert \frac{x_i}n
-\frac{y_j}m \vert:j=1,..,k\}\]</span></p>
<p>This test was first proposed in <span class="citation">(Kolmogorov
1933)</span>, <span class="citation">(Smirnov 1939)</span> and is one of
the most widely used tests today.</p>
<p>There is a close connection between the edf’s and the ranks of the x
and y in the combined data set. Using this one can also calculate the KS
statistic, and many statistics to follow, based on these ranks. This is
used in many software routines, for example the ks.test routine in R.
However, when applied to discrete data these formulas can fail badly
because of the many ties, and so we will not use them in our
routine.</p>
<ul>
<li><strong>Kuiper</strong> Kuiper’s test</li>
</ul>
<p>This test is closely related to Kolmogorov-Smirnov, but it uses the
sum of the largest positive and negative differences between the edf’s
as a test statistic:</p>
<p><span class="math display">\[T_x=\sum_{i=1}^{j} \vert \frac1n I\{z_i
\in x\}-\frac1m I\{z_i \in x\} \vert:j=1,..,n\]</span> <span class="math display">\[T_y=\sum_{i=1}^{j} \vert \frac1n I\{z_i \in
y\}-\frac1m I\{z_i \in y\} \vert:j=1,..,m\]</span> and the the test
statistic is <span class="math inline">\(T_x-T_y\)</span>. The discrete
case follows directly. This test was first proposed in <span class="citation">(Kuiper 1960)</span>.</p>
<ul>
<li><strong>CvM</strong> Cramer-vonMises test</li>
</ul>
<p>This test is based on the integrated squared difference between the
edf’s:</p>
<p><span class="math display">\[\frac{nm}{(n+m)^2}\sum_{i=1}^{n+m}
\left( \hat{F}(z_i)-\hat{G}(z_i) \right)^2 \]</span> the extension to
the two-sample problem of the Cramer-vonMises criterion is discussed in
<span class="citation">(T. W. Anderson 1962)</span>.</p>
<ul>
<li><strong>AD</strong> Anderson-Darling test</li>
</ul>
<p>This test is based on</p>
<p><span class="math display">\[nm\sum_{i=1}^{n+m-1} \frac{\left(
\hat{F}(z_i)-\hat{G}(z_i) \right)^2}{i(n-i)} \]</span></p>
<p>It was first proposed in <span class="citation">(Theodore W.
Anderson, Darling, et al. 1952)</span>.</p>
<ul>
<li><strong>LR</strong> Lehmann-Rosenblatt test</li>
</ul>
<p>Let <span class="math inline">\(r_i\)</span> and <span class="math inline">\(s_i\)</span> be the ranks of x and y in the
combined sample, then the test statistic is given by</p>
<p><span class="math display">\[\frac1{nm(n+m)}\left[n\sum_{i=1}^n(r_i-1)^2+m\sum_{i=1}^m(s_i-1)^2\right]\]</span>
<span class="citation">(Lehmann 1951)</span> and <span class="citation">(Rosenblatt 1952)</span></p>
<ul>
<li><strong>ZA, ZK and ZC</strong> Zhang’s tests</li>
</ul>
<p>These tests are based on the paper <span class="citation">(Zhang
2006)</span>. Note that the calculation of <em>ZC</em> is the one
exception from the rule: even in the discrete data case the calculation
of the test statistic does require loops of lengths n and m. The
calculation time will therefore increase with the sample sizes, and for
very large data sets this test might have to be excluded.</p>
<ul>
<li><strong>Wassp1</strong> Wasserstein p=1 test</li>
</ul>
<p>A test based on the Wasserstein p1 metric. It compares the quantiles
of the x and y in the combined data set. If n=m the test statistic in
the continuous case is very simple:</p>
<p><span class="math display">\[ \frac1n\sum_{i=1}^n |x_i-y_i|\]</span>
If <span class="math inline">\(n\ne m\)</span> it is first necessary to
find the respective quantiles of the x’s and y’s in the combined data
set. In the discrete case the test statistic is</p>
<p><span class="math display">\[\sum_{i=1}^{k-1} \vert
\sum_{j=1}^i\frac{x_j}{n}-\sum_{j=1}^i\frac{y_j}{m}  \vert(v_{i+1}-v_i)\]</span></p>
<p>For a discussion of the Wasserstein distance see <span class="citation">(Vaserstein 1969)</span>.</p>
<div id="the-arguments-of-twosample_test" class="section level4">
<h4>The Arguments of <em>twosample_test</em></h4>
<p>The routine has the following arguments:</p>
<ul>
<li><p><strong>x</strong> and <strong>y</strong> are numeric vectors. In
the continuous data case they are simply the data, in the discrete case
the counts.</p></li>
<li><p><strong>vals</strong> a numeric vector of values of the discrete
random variable. If missing continuous data is assumed. In the discrete
case x, y and vals have to be vectors of equal length.</p></li>
<li><p><strong>TS</strong> a routine to calculate a test statistic. If
missing built-in tests are used.</p></li>
<li><p><strong>TSextra</strong> a list to be passed to TS.</p></li>
<li><p><strong>wx,wy</strong> weights for data set (optional)</p></li>
<li><p><strong>B=5000</strong> number of simulation runs for permutation
test. If B=0 only test statistics are found.</p></li>
<li><p><strong>nbins=c(50, 10)</strong> number of bins to use for
chi-square test. In the continuous data case bins are found
equi-probable via the quantiles of the combined data set. In the
discrete case nbins[1] is changed to the number of values, so the
chi-square test is done on the original data set. Then neighboring
values are combined until there are nbins[2] classes.</p></li>
<li><p><strong>minexpcount=5</strong> minimum expected counts reuired
for chi sqaure tests</p></li>
<li><p><strong>maxProcessor</strong> if &gt;1 parallel computing is
used.</p></li>
<li><p><strong>UseLargeSample</strong> for large data sets (&gt;10000)
use methods which have large sample theories to find p values.</p></li>
<li><p><strong>samplingmethod</strong> independence or MCMC for discrete
data</p></li>
<li><p><strong>rnull</strong> routine to generate data for parametric
bootstrap.</p></li>
<li><p><strong>SuppressMessages=FALSE</strong> suppress informative
messages</p></li>
<li><p><strong>doMethods</strong> a character vector giving the names of
the methods to include.</p></li>
</ul>
<p>Say for example we want to use only the KS and AD tests:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>x<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">10</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">12</span>)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="fu">twosample_test</span>(x, y, <span class="at">B=</span><span class="dv">500</span>, <span class="at">doMethods=</span><span class="fu">c</span>(<span class="st">&quot;KS&quot;</span>,<span class="st">&quot;AD&quot;</span>))</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co">#&gt; $statistics</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co">#&gt;        KS        AD </span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co">#&gt; 0.4333333 1.3538157 </span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co">#&gt; $p.values</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co">#&gt; KS AD </span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="co">#&gt;  0  0</span></span></code></pre></div>
</div>
<div id="the-output-of-twosample_test" class="section level3">
<h3>The Output of <em>twosample_test</em></h3>
<p>A list with vectors statistics (the test statistics) and p
values.</p>
</div>
<div id="shiny-app" class="section level3">
<h3><em>shiny app</em></h3>
<p>The tests can also be run via a shiny app. To do so run</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">run_shiny</span>()</span></code></pre></div>
</div>
<div id="twosample_power-and-plot_power" class="section level3">
<h3><strong>twosample_power</strong> and
<strong>plot_power</strong></h3>
<p>The routine <em>twosample_power</em> allows the estimation of the
power of the various tests, and <em>plot_power</em> draws the
corresponding power graph with the methods sorted by their mean
power.</p>
<p>Note that due to the use of permutation tests the power calculations
are fairly slow. Because of the time constraints imposed by CRAN the
following routines are not run. A full power study with (say) 25
alternatives and fairly large data sets might take several hours to
run.</p>
<p>New tests can be used in the same way as above.</p>
</div>
<div id="example-4" class="section level3">
<h3>Example 4</h3>
<p>Say we wish to find the powers of the tests when one data set comes
from a standard normal distribution with sample size 100 and the other
from a t distribution with 1-10 degrees of freedom and sample size
200.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">plot_power</span>(<span class="fu">twosample_power</span>(</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="at">f=</span><span class="cf">function</span>(df) <span class="fu">list</span>(<span class="at">x=</span><span class="fu">rnorm</span>(<span class="dv">100</span>), <span class="at">y=</span><span class="fu">rt</span>(<span class="dv">200</span>, df)), <span class="at">df=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>)</span></code></pre></div>
<div id="the-arguments-of-twosample_power" class="section level4">
<h4>The Arguments of <em>twosample_power</em></h4>
<p>The arguments TS, TSextra, nbins, minexpcount , UseLargeSample,
samplingmethod, rnull, SuppressMessages, maxProcessor and B are the same
as in <em>twosample_test</em>. In addtion we have</p>
<ul>
<li><p><strong>f</strong> A function that generates data sets x and y,
either continuous or the counts of discrete variables. In the discrete
case care needs to be taken that the resulting vectors have the same
length as <em>vals</em>. The output has to be a list with elements x and
y. In the case of discrete data the list also has to include a vector
<strong>vals</strong>, the values of the discrete variable.</p></li>
<li><p><strong>…</strong> arguments passed to f. The most common case
would be a single vector, but two vectors or none is also
possible.</p></li>
<li><p><strong>alpha=0.05</strong> type I error probability to use in
power calculation</p></li>
</ul>
<p>The arguments of <strong>plot_power</strong> are a matrix of powers
created by <strong>twosample_power</strong> and (optional) Smooth=FALSE
if no smoothing is desired and a name of the variable on the x axis.</p>
</div>
</div>
<div id="example-5" class="section level3">
<h3>Example 5</h3>
<p>We wish to find the powers of the tests when the data set x are 100
observations comes from a binomial n=10, p=0.5 and y 120 observations
from from a binomial n=10 and a number of different success
probabilities p. Note that in either case not all the possible values
0-10 will actually appear in every data set, so we need to take some
care in assuring that x, y and vals match every time:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">plot_power</span>(<span class="fu">twosample_power</span>(</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>  <span class="cf">function</span>(p) {</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>    vals<span class="ot">=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>    x<span class="ot">=</span><span class="fu">table</span>(<span class="fu">c</span>(vals, <span class="fu">rbinom</span>(<span class="dv">100</span>, <span class="dv">10</span>, <span class="fl">0.5</span>))) <span class="sc">-</span> <span class="dv">1</span> <span class="co">#Make sure each vector has length 11</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>    y<span class="ot">=</span><span class="fu">table</span>(<span class="fu">c</span>(vals, <span class="fu">rbinom</span>(<span class="dv">120</span>, <span class="dv">10</span>, p))) <span class="sc">-</span> <span class="dv">1</span>  <span class="co">#and names 1-10</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    vals<span class="ot">=</span>vals[x<span class="sc">+</span>y<span class="sc">&gt;</span><span class="dv">0</span>] <span class="co"># only vals with at least one count</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">x=</span>x[<span class="fu">as.character</span>(vals)],<span class="at">y=</span>y[<span class="fu">as.character</span>(vals)], <span class="at">vals=</span>vals)</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>  },</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>  <span class="at">p=</span><span class="fu">seq</span>(<span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="at">length=</span><span class="dv">5</span>)</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>), <span class="st">&quot;p&quot;</span>)</span></code></pre></div>
</div>
<div id="example-6" class="section level3">
<h3>Example 6</h3>
<p>We want to assess the effect of the sample size when one data set
comes from a standard normal and the other from a normal with mean 1 and
standard deviation 1:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">plot_power</span>(<span class="fu">twosample_power</span>(</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  <span class="at">f=</span><span class="cf">function</span>(n) <span class="fu">list</span>(<span class="at">x=</span><span class="fu">rnorm</span>(n), <span class="at">y=</span><span class="fu">rnorm</span>(n, <span class="dv">1</span>)),</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>  <span class="at">n=</span><span class="dv">10</span><span class="sc">*</span><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>), <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
</div>
<div id="adjusted-p-values-for-several-tests" class="section level3">
<h3>Adjusted p values for Several Tests</h3>
<p>As no single test can be relied upon to consistently have good power,
it is reasonable to employ several of them. We would then reject the
null hypothesis if any of the tests does so, that is, if the smallest
p-value is less than the desired type I error probability <span class="math inline">\(\alpha\)</span>.</p>
<p>This procedure clearly suffers from the problem of simultaneous
inference, and the true type I error probability will be much larger
than <span class="math inline">\(\alpha\)</span>. It is however possible
to adjust the p value so it does achieve the desired <span class="math inline">\(\alpha\)</span>. This can be done as follows:</p>
<p>We generate a number of data sets under the null hypothesis.
Generally about 1000 will be sufficient. Then for each simulated data
set we apply the tests we wish to include, and record the smallest p
value. Here is an example. .</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>pvals<span class="ot">=</span><span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">1000</span>,<span class="dv">13</span>)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) </span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>  pvals[i, ]<span class="ot">=</span>R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(<span class="fu">runif</span>(<span class="dv">100</span>), <span class="fu">runif</span>(<span class="dv">100</span>), <span class="at">B=</span><span class="dv">1000</span>)<span class="sc">$</span>p.values</span></code></pre></div>
<p>Next we find the smallest p value in each run for two selections of
four methods. One is the selection found to be best above, namely
Zhang’s ZC and ZK methods, the methods by Kuiper and Wasserstein as well
as a chi square test with a small number of bins. As a second selection
we use the methods by Kolmogorov-Smirnov, Kuiper, Anderson-Darling,
Cramer-vonMises and Lehman-Rosenblatt, which for this null data turn out
to be highly correlated.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">colnames</span>(pvals)<span class="ot">=</span><span class="fu">names</span>(R2sample<span class="sc">::</span><span class="fu">twosample_test</span>(<span class="fu">runif</span>(<span class="dv">100</span>), <span class="fu">runif</span>(<span class="dv">100</span>), <span class="at">B=</span><span class="dv">1000</span>)<span class="sc">$</span>p.values)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>p1<span class="ot">=</span><span class="fu">apply</span>(pvals[, <span class="fu">c</span>(<span class="st">&quot;ZK&quot;</span>, <span class="st">&quot;ZC&quot;</span>, <span class="st">&quot;Wassp1&quot;</span>, <span class="st">&quot;Kuiper&quot;</span>, <span class="st">&quot;ES small&quot;</span> )], <span class="dv">1</span>, min)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>p2<span class="ot">=</span><span class="fu">apply</span>(pvals[, <span class="fu">c</span>(<span class="st">&quot;KS&quot;</span>, <span class="st">&quot;Kuiper&quot;</span>, <span class="st">&quot;AD&quot;</span>, <span class="st">&quot;CvM&quot;</span>, <span class="st">&quot;LR&quot;</span>)], <span class="dv">1</span>, min)</span></code></pre></div>
<p>Next we find the empirical distribution function for the two sets of
p values and draw their graphs. We also add the curves for the cases of
four identical tests and the case of four independent tests, which of
course is the Bonferroni correction. The data for the cdfs is in the
inst/extdata directory of the package.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>tmp<span class="ot">=</span>R2sample<span class="sc">::</span>pvaluecdf</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>Tests<span class="ot">=</span><span class="fu">factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;Identical Tests&quot;</span>, <span class="fu">nrow</span>(tmp)),</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;Correlated Selection&quot;</span>, <span class="fu">nrow</span>(tmp)),</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;Best Selection&quot;</span>, <span class="fu">nrow</span>(tmp)),</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>        <span class="fu">rep</span>(<span class="st">&quot;Independent Tests&quot;</span>, <span class="fu">nrow</span>(tmp))),</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>        <span class="at">levels=</span><span class="fu">c</span>(<span class="st">&quot;Identical Tests&quot;</span>,  <span class="st">&quot;Correlated Selection&quot;</span>, </span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>                 <span class="st">&quot;Best Selection&quot;</span>, <span class="st">&quot;Independent Tests&quot;</span>),</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>        <span class="at">ordered =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>dta<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">x=</span><span class="fu">c</span>(tmp[,<span class="dv">1</span>],tmp[,<span class="dv">1</span>],tmp[,<span class="dv">1</span>],tmp[,<span class="dv">1</span>]),</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a>          <span class="at">y=</span><span class="fu">c</span>(tmp[,<span class="dv">1</span>],tmp[,<span class="dv">3</span>],tmp[,<span class="dv">2</span>],<span class="dv">1</span><span class="sc">-</span>(<span class="dv">1</span><span class="sc">-</span>tmp[,<span class="dv">1</span>])<span class="sc">^</span><span class="dv">4</span>),</span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>          <span class="at">Tests=</span>Tests)</span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">ggplot</span>(<span class="at">data=</span>dta, ggplot2<span class="sc">::</span><span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y,<span class="at">col=</span>Tests))<span class="sc">+</span></span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>  ggplot2<span class="sc">::</span><span class="fu">geom_line</span>(<span class="at">linewidth=</span><span class="fl">1.2</span>)<span class="sc">+</span></span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>  ggplot2<span class="sc">::</span><span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;p value&quot;</span>, <span class="at">y=</span><span class="st">&quot;CDF&quot;</span>)<span class="sc">+</span></span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a>  ggplot2<span class="sc">::</span><span class="fu">scale_color_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;red&quot;</span>, <span class="st">&quot;Orange&quot;</span>, <span class="st">&quot;green&quot;</span>))</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="case-studies" class="section level3">
<h3>Case Studies</h3>
<p>The package includes the routine <em>run.studies</em>, which provides
20 case studies each for the continuous and the discrete case. This
allows the user to easily compare the power of the methods included in
the package to a different one of their choice.</p>
<p>Say a user wishes to study the performance of the chi-square test,
implemented in <em>chitest</em>. Of course this test is already
implemented in <em>R2sample</em>, so this is for illustration only. Say
we wish to see its performance when compared to the tests implemented in
<em>R2sample</em> for the case where the null hypothesis specifies a
uniform distribution but the data actually comes from a linear
distribution with slope s:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>chitest <span class="ot">=</span> <span class="cf">function</span>(x, y, TSextra) {</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>   nbins<span class="ot">=</span>TSextra<span class="sc">$</span>nbins</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>   nx<span class="ot">=</span><span class="fu">length</span>(x);ny<span class="ot">=</span><span class="fu">length</span>(y);n<span class="ot">=</span>nx<span class="sc">+</span>ny</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>   xy<span class="ot">=</span><span class="fu">c</span>(x,y)</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>   bins<span class="ot">=</span><span class="fu">quantile</span>(xy, (<span class="dv">0</span><span class="sc">:</span>nbins)<span class="sc">/</span>nbins)</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>   Ox<span class="ot">=</span><span class="fu">hist</span>(x, bins, <span class="at">plot=</span><span class="cn">FALSE</span>)<span class="sc">$</span>counts</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>   Oy<span class="ot">=</span><span class="fu">hist</span>(y, bins, <span class="at">plot=</span><span class="cn">FALSE</span>)<span class="sc">$</span>counts</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>   tmp<span class="ot">=</span><span class="fu">sqrt</span>(<span class="fu">sum</span>(Ox)<span class="sc">/</span><span class="fu">sum</span>(Oy))</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>   chi <span class="ot">=</span> <span class="fu">sum</span>((Ox<span class="sc">/</span>tmp<span class="sc">-</span>Oy<span class="sc">*</span>tmp)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(Ox<span class="sc">+</span>Oy))</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a>   pval<span class="ot">=</span><span class="dv">1</span><span class="sc">-</span><span class="fu">pchisq</span>(chi, nbins<span class="dv">-1</span>)</span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>   out<span class="ot">=</span><span class="fu">ifelse</span>(TSextra<span class="sc">$</span>statistic,chi,pval)</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>   <span class="fu">names</span>(out)<span class="ot">=</span><span class="st">&quot;ChiSquare&quot;</span></span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a>   out</span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a>}</span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a>TSextra<span class="ot">=</span><span class="fu">list</span>(<span class="at">nbins=</span><span class="dv">5</span>,<span class="at">statistic=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>pwr<span class="ot">=</span>R2sample<span class="sc">::</span><span class="fu">run.studies</span>(chitest, <span class="st">&quot;uniform.linear&quot;</span>, <span class="at">TSextra=</span>TSextra, <span class="at">With.p.value =</span> <span class="cn">TRUE</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="co">#&gt; Running case study uniform.linear.cont ...</span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">plot_power</span>(pwr, <span class="st">&quot;slope&quot;</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>Arguments of <em>run.studies</em>:</p>
<ul>
<li>TS: new test statistic<br />
</li>
<li>study: either the name(s) or position(s) of the desired sudies in
the list of all studies<br />
</li>
<li>TSextra: a list passed to TS</li>
<li>With.p.value =FALSE set to TRUE if the new method finds p value(s).
TS should then return only those<br />
</li>
<li>BasicComparison=TRUE: All 20 case studies are run for one value of
the parameter under the alternative.<br />
</li>
<li>nsample=500: sample size<br />
</li>
<li>alpha=0.05: true type I error probability<br />
</li>
<li>param_alt: a vector of values of the parameter of the alternative
distribution. If missing the ones included in R2sample are used. If more
than one study is run this needs to be a list of vectors<br />
</li>
<li>B=1000 number of simulation runs</li>
</ul>
<p>Arguments of routine to calculate new test:</p>
<ul>
<li><p>Continuous data:<br />
x,y the two data sets<br />
TSextra (optional): a list passed to the routine with any object needed
to do the calculation.</p></li>
<li><p>Discrete data:<br />
x,y the two data sets<br />
vals: the possible values of the discrete random variable<br />
TSextra (optional): a list passed to the routine with any object needed
to do the calculation.</p></li>
</ul>
<p>The output of the routine has to be a named vector with either the
test statistic(s) or the p value(s).</p>
<p>The case studies are as follows. In each the first term specifies the
model under the null hypothesis and the second the model under the
alternative hypothesis.</p>
<ol style="list-style-type: decimal">
<li><p>uniform.linear<span class="math inline">\(\hspace{3cm}\)</span>
U[0,1] vs a linear model on [0,1] with slope s.</p></li>
<li><p>uniform.quadratic<span class="math inline">\(\hspace{2.5cm}\)</span> U[0,1] vs a quadratic
model with vertex at 0.5 and some curvature a.</p></li>
<li><p>uniform.bump<span class="math inline">\(\hspace{3.1cm}\)</span>
U[0,1] vs U[0,1]+N(0.5,0.05).</p></li>
<li><p>uniform.sine<span class="math inline">\(\hspace{3.3cm}\)</span>
U[0,1] vs U[0,1]+Sine wave</p></li>
<li><p>beta22.betaaa<span class="math inline">\(\hspace{3cm}\)</span>
Beta(2,2) vs Beta(a,a)</p></li>
<li><p>beta22.beta2a<span class="math inline">\(\hspace{3cm}\)</span>
Beta(2,2) vs Beta(2,a)</p></li>
<li><p>normal.shift<span class="math inline">\(\hspace{3.5cm}\)</span>
N(0,1) vs N(<span class="math inline">\(\mu\)</span>,1)</p></li>
<li><p>normal.stretch<span class="math inline">\(\hspace{3.1cm}\)</span>
N(0,1) vs N(0, <span class="math inline">\(\sigma\)</span>)</p></li>
<li><p>normal.t<span class="math inline">\(\hspace{4.2cm}\)</span>
N(0,1) vs t(df)</p></li>
<li><p>normal.outlier1<span class="math inline">\(\hspace{3.1cm}\)</span> N(0,1) vs
N(0,1)+U[2,3]</p></li>
<li><p>normal.outlier2<span class="math inline">\(\hspace{3.1cm}\)</span> N(0,1) vs
N(0,1)+U[-3,-2]+U[2,3]</p></li>
<li><p>exponential.gamma<span class="math inline">\(\hspace{2.3cm}\)</span> Exp(1) vs
Gamma(1,b)</p></li>
<li><p>exponential.weibull<span class="math inline">\(\hspace{2.5cm}\)</span> Exp(1) vs
Weibull(1,b)</p></li>
<li><p>exponential.bump<span class="math inline">\(\hspace{2.7cm}\)</span> Exp(1) vs
Exp(1)+N(0.5,0.05)</p></li>
<li><p>gamma.normal<span class="math inline">\(\hspace{3.1cm}\)</span>
Gamma(<span class="math inline">\(\mu\)</span>) vs N(<span class="math inline">\(\bar{x}\)</span>, sd(x)), here the mean of the
normal distribution are the sample mean and sample standard deviation of
the x data set.</p></li>
<li><p>normal.normalmixture<span class="math inline">\(\hspace{2.1cm}\)</span> N(0,1) vs N(<span class="math inline">\(-\mu\)</span>,1)+N(<span class="math inline">\(\mu\)</span>,1)</p></li>
<li><p>uniform.uniformmixture<span class="math inline">\(\hspace{1.9cm}\)</span> U[0,1] vs. <span class="math inline">\(\alpha\)</span>U[0,1/2]+(1-<span class="math inline">\(\alpha\)</span>)U[1/2,1]</p></li>
<li><p>uniform.betamixture<span class="math inline">\(\hspace{2.5cm}\)</span> U[0,1] vs. <span class="math inline">\(\alpha\)</span>U[0,1/2]+(1-<span class="math inline">\(\alpha\)</span>)Beta(2,2)</p></li>
<li><p>chisquare.noncentral<span class="math inline">\(\hspace{2.3cm}\)</span> <span class="math inline">\(\chi^2(5)\)</span> vs. <span class="math inline">\(\chi^2(5, \tau)\)</span></p></li>
<li><p>uniform.triangular<span class="math inline">\(\hspace{2.9cm}\)</span> U[0,1]
vs. triangular</p></li>
</ol>
<p>Generally a user will wish to apply their test to all the case
studies. This can be done easily with:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">run.studies</span>(chitest, <span class="at">TSextra=</span>TSextra, <span class="at">With.p.value=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><em>run.studies</em> can also be used to run the studies for the
included methods but for different values of param_alt, nsample and/or
alpha. For example, say we wish to find the powers of the included
continuous methods for the cases uniform.linear and uniform.quadratic as
well as samples of size 2000 and a true type I error of 0.1. Moreover
for the case uniform/linear we want the slopes to be 0.1 and 0.2 and for
the case uniform.quadratic we want param_alt to be 1.3:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>R2sample<span class="sc">::</span><span class="fu">run.studies</span>(<span class="cn">TRUE</span>, <span class="co"># continuous data/model</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>        <span class="at">study=</span><span class="fu">c</span>(<span class="st">&quot;uniform.linear&quot;</span>, <span class="st">&quot;uniform.quadratic&quot;</span>),</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>        <span class="at">param_alt=</span><span class="fu">list</span>(<span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.2</span>), <span class="fl">1.3</span>),</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>        <span class="at">nsample=</span><span class="dv">2000</span>,</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>        <span class="at">alpha=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Anderson1962" class="csl-entry">
Anderson, T. W. 1962. <span>“On the Distribution of the Two_sample
Cramer-von Mises Criterion.”</span> <em>The Annals of Mathematical
Statistics</em> 33(3): 1148–59.
</div>
<div id="ref-anderson1952" class="csl-entry">
Anderson, Theodore W, Donald A Darling, et al. 1952. <span>“Asymptotic
Theory of Certain Goodness of Fit Criteria Based on Stochastic
Processes.”</span> <em>The Annals of Mathematical Statistics</em> 23
(2): 193–212.
</div>
<div id="ref-Kolmogorov1933" class="csl-entry">
Kolmogorov, A. N. 1933. <span>“Sulla Determinazione Empirica Di Una
Legge Di Distribuzione.”</span> <em>Giornale Dell’Instituto Italiano
Degli Attuari</em> 4: 83–91.
</div>
<div id="ref-Kuiper1960" class="csl-entry">
Kuiper, N. H. 1960. <span>“Tests Concerning Random Points on a
Circle.”</span> <em>Proceedings of the Koninklijke Nederlandse Akademie
van Wetenschappen</em> 63: 38–47.
</div>
<div id="ref-lehmann1951" class="csl-entry">
Lehmann, E. L. 1951. <span>“Consistency and Unbiasedness of Certain
Nonparametric Tests.”</span> <em>Ann. MAth. Statist.</em> 22(1): 165–79.
</div>
<div id="ref-rosenblatt1952" class="csl-entry">
Rosenblatt, M. 1952. <span>“Limit Theorems Associated with Variants of
the von Mises Statistic.”</span> <em>Ann. Math. Statist.</em> 23:
617–23.
</div>
<div id="ref-Smirnov1939" class="csl-entry">
Smirnov, N. V. 1939. <span>“Estimate of Deviation Between Empirical
Distribution Functions in Two Independent Samples.”</span> <em>Bull.
Moscow Univ.</em> 2: 3–16.
</div>
<div id="ref-wasserstein1969" class="csl-entry">
Vaserstein, L. N. 1969. <span>“Markov Processes over Denumerable
Products of Spaces, Describing Large Systems of Automata.”</span>
<em>Problemy Peredachi Informatsii</em> 5(3): 64–72.
</div>
<div id="ref-rolke2021" class="csl-entry">
W. Rolke, C. Gutierrez Gongora. 2021. <span>“A Chi-Square
Goodness-of-Fit Test for Continuous Distributions Against a Known
Alternative.”</span> <em>Computational Statistics</em>.
</div>
<div id="ref-zhang2006" class="csl-entry">
Zhang, J. 2006. <span>“Powerful Two Sample Tests Based on the Likelihood
Ratio.”</span> <em>Techometrics</em> 48: 95–103.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
